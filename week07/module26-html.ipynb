{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing HTML with BeautifulSoup\n",
    "\n",
    "In this example, we want to look at a website and get a list of all the available downloadable files from that website.\n",
    "\n",
    "https://catalog.data.gov/dataset?res_format=CSV&tags=hospital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://www.healthdata.gov/browse?q=new%20york%20city&sortBy=relevance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = {}\n",
    "\n",
    "for num, item in enumerate(soup.find_all('a', {'class': 'browse2-result-name-link'})):\n",
    "    if num > 10:\n",
    "        break\n",
    "    result_list[item.text] = item.attrs.get('href')\n",
    "    \n",
    "result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://fhir.epic.com/Specifications?api=981')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {\n",
    "#   '4100': ['Fatal', 'The resource request contained an invalid parmater', 'example']\n",
    "# }\n",
    "\n",
    "output = {}\n",
    "\n",
    "for table in soup.find_all('table', {'class': 'api-documentation-table'}):\n",
    "#     print(\"Found a table\")\n",
    "    \n",
    "    headers = []\n",
    "    for header in table.find_all('th'):\n",
    "        headers.append(header.text)\n",
    "        \n",
    "    if headers == ['Error Code', 'Severity', 'Description', 'Example']:\n",
    "        for row in table.find_all('tr'):\n",
    "            data = [x.text for x in list(row.find_all('td'))]\n",
    "            if len(data) != 0:\n",
    "                code = data[0]\n",
    "                severity = data[1]\n",
    "                description = data[2]\n",
    "                example = data[3]\n",
    "                output[code] = [severity, description, example]\n",
    "             \n",
    "import json\n",
    "\n",
    "print(json.dumps(output, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tables = pd.read_html('https://fhir.epic.com/Specifications?api=981')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://catalog.data.gov/dataset?res_format=CSV&tags=hospital')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r.text[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in soup.find_all('h3'):\n",
    "    print(link.a.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in soup.find_all('li', 'dataset-item'):\n",
    "    name = element.h3.text.strip()\n",
    "    resources = element.ul\n",
    "    for item in resources.find_all('li'):\n",
    "        if item.text.strip() == 'CSV':\n",
    "            print(\"Download information about '{}' from {}\".format(name,item.a.attrs['href']))\n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Table Data\n",
    "\n",
    "\n",
    "In this example, we're going to find an HTML table and extract the data from that table\n",
    "\n",
    "https://open.epic.com/Clinical/Allergy - Error Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url = 'https://open.epic.com/Clinical/Allergy'\n",
    "r  = requests.get(url)\n",
    "data = r.text\n",
    "\n",
    "soup = BeautifulSoup(data)\n",
    "\n",
    "table = soup.find('table',id='errors')\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In HTML tables, there is usually a <thead> section to tell us what the column headers are.\n",
    "# Let's load those into a simple list of headers[]\n",
    "headers = []\n",
    "for cell in table.thead.tr.find_all('th'):\n",
    "    headers.append(cell.text)\n",
    "\n",
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In HTML tables, the rows are in a <tbody> section\n",
    "errors = {}\n",
    "for row in table.tbody.find_all('tr'):\n",
    "    colnum = 0\n",
    "    for cell in row.find_all('td'):\n",
    "        if colnum == 0:\n",
    "            error_cd = cell.text\n",
    "            errors.setdefault(error_cd, {})\n",
    "        else:\n",
    "            column = headers[colnum]\n",
    "            errors[error_cd][column] = cell.text\n",
    "        colnum += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(errors, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors.get('4119')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors.get('4119')['Severity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading HTML Tables with Pandas\n",
    "\n",
    "Pandas has the ability to read HTML, too.  In ideal circumstances, it will scour whatever page you give it and find all of the tables there.  The result from `read_html()` will be a list of dataframes.\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.read_html.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = pd.read_html('https://open.epic.com/Clinical/Allergy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
